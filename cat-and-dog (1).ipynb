{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2032f076",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-02T12:43:39.906713Z",
     "iopub.status.busy": "2025-08-02T12:43:39.906209Z",
     "iopub.status.idle": "2025-08-02T12:44:03.419371Z",
     "shell.execute_reply": "2025-08-02T12:44:03.418539Z"
    },
    "papermill": {
     "duration": 23.52116,
     "end_time": "2025-08-02T12:44:03.420900",
     "exception": false,
     "start_time": "2025-08-02T12:43:39.899740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-02 12:43:41.354184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754138621.545132      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754138621.598366      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73ca3d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:44:03.431283Z",
     "iopub.status.busy": "2025-08-02T12:44:03.430870Z",
     "iopub.status.idle": "2025-08-02T12:44:39.425480Z",
     "shell.execute_reply": "2025-08-02T12:44:39.424861Z"
    },
    "papermill": {
     "duration": 36.000983,
     "end_time": "2025-08-02T12:44:39.426873",
     "exception": false,
     "start_time": "2025-08-02T12:44:03.425890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754138664.841529      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory ='/kaggle/input/dog-vs-cat-classification/train/train',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=16,\n",
    "    image_size=(256,256)\n",
    "    \n",
    ")\n",
    "validation_ds= keras.utils.image_dataset_from_directory(\n",
    "    directory ='/kaggle/input/dog-vs-cat-classification/test',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=16,\n",
    "    image_size=(256,256)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1b87ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:44:39.437108Z",
     "iopub.status.busy": "2025-08-02T12:44:39.436867Z",
     "iopub.status.idle": "2025-08-02T12:44:39.482241Z",
     "shell.execute_reply": "2025-08-02T12:44:39.481528Z"
    },
    "papermill": {
     "duration": 0.05175,
     "end_time": "2025-08-02T12:44:39.483367",
     "exception": false,
     "start_time": "2025-08-02T12:44:39.431617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation= keras.utils.image_dataset_from_directory(\n",
    "    directory ='/kaggle/input/cats-and-dogs/val',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=16,\n",
    "    image_size=(256,256)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9575dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:44:39.493722Z",
     "iopub.status.busy": "2025-08-02T12:44:39.493282Z",
     "iopub.status.idle": "2025-08-02T12:44:39.556897Z",
     "shell.execute_reply": "2025-08-02T12:44:39.556349Z"
    },
    "papermill": {
     "duration": 0.070099,
     "end_time": "2025-08-02T12:44:39.558097",
     "exception": false,
     "start_time": "2025-08-02T12:44:39.487998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 275 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds_data= keras.utils.image_dataset_from_directory(\n",
    "    directory ='/kaggle/input/cats-and-dogs/train',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=16,\n",
    "    image_size=(256,256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9438985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:44:39.568578Z",
     "iopub.status.busy": "2025-08-02T12:44:39.568320Z",
     "iopub.status.idle": "2025-08-02T12:44:39.574933Z",
     "shell.execute_reply": "2025-08-02T12:44:39.574400Z"
    },
    "papermill": {
     "duration": 0.012967,
     "end_time": "2025-08-02T12:44:39.575955",
     "exception": false,
     "start_time": "2025-08-02T12:44:39.562988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming train_ds and train_ds_data are already defined as in your code\n",
    "merged_ds = train_ds.concatenate(train_ds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe2508a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:44:39.586696Z",
     "iopub.status.busy": "2025-08-02T12:44:39.586454Z",
     "iopub.status.idle": "2025-08-02T12:44:39.591484Z",
     "shell.execute_reply": "2025-08-02T12:44:39.590811Z"
    },
    "papermill": {
     "duration": 0.01194,
     "end_time": "2025-08-02T12:44:39.592639",
     "exception": false,
     "start_time": "2025-08-02T12:44:39.580699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_ds = merged_ds.shuffle(buffer_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f3b1ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:44:39.602369Z",
     "iopub.status.busy": "2025-08-02T12:44:39.602145Z",
     "iopub.status.idle": "2025-08-02T12:44:39.607273Z",
     "shell.execute_reply": "2025-08-02T12:44:39.606744Z"
    },
    "papermill": {
     "duration": 0.011233,
     "end_time": "2025-08-02T12:44:39.608334",
     "exception": false,
     "start_time": "2025-08-02T12:44:39.597101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train_ds: 1563\n",
      "Number of batches in train_ds_data: 18\n",
      "Number of batches in merged_ds: 1581\n"
     ]
    }
   ],
   "source": [
    "# Count the number of batches in each dataset\n",
    "num_batches_train_ds = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_batches_train_ds_data = tf.data.experimental.cardinality(train_ds_data).numpy()\n",
    "num_batches_merged = tf.data.experimental.cardinality(merged_ds).numpy()\n",
    "\n",
    "print(f\"Number of batches in train_ds: {num_batches_train_ds}\")\n",
    "print(f\"Number of batches in train_ds_data: {num_batches_train_ds_data}\")\n",
    "print(f\"Number of batches in merged_ds: {num_batches_merged}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555210d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:44:39.618322Z",
     "iopub.status.busy": "2025-08-02T12:44:39.618116Z",
     "iopub.status.idle": "2025-08-02T12:44:39.679962Z",
     "shell.execute_reply": "2025-08-02T12:44:39.679218Z"
    },
    "papermill": {
     "duration": 0.068195,
     "end_time": "2025-08-02T12:44:39.681187",
     "exception": false,
     "start_time": "2025-08-02T12:44:39.612992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "merged_ds = merged_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "validation_new_ds = validation.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db145fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:44:39.691471Z",
     "iopub.status.busy": "2025-08-02T12:44:39.691254Z",
     "iopub.status.idle": "2025-08-02T12:44:39.716650Z",
     "shell.execute_reply": "2025-08-02T12:44:39.715827Z"
    },
    "papermill": {
     "duration": 0.031546,
     "end_time": "2025-08-02T12:44:39.717692",
     "exception": true,
     "start_time": "2025-08-02T12:44:39.686146",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/2742306722.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Pred: {preds[i].numpy()[0]}, Actual: {labels[i].numpy()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    ax = plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(f\"Pred: {preds[i].numpy()[0]}, Actual: {labels[i].numpy()}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a562a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:20:44.042532Z",
     "iopub.status.busy": "2025-08-02T11:20:44.041901Z",
     "iopub.status.idle": "2025-08-02T11:20:44.938879Z",
     "shell.execute_reply": "2025-08-02T11:20:44.938391Z",
     "shell.execute_reply.started": "2025-08-02T11:20:44.042509Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='valid', activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a1930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:21:00.615822Z",
     "iopub.status.busy": "2025-08-02T11:21:00.615068Z",
     "iopub.status.idle": "2025-08-02T11:21:00.629012Z",
     "shell.execute_reply": "2025-08-02T11:21:00.628471Z",
     "shell.execute_reply.started": "2025-08-02T11:21:00.615797Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482b202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:21:19.471687Z",
     "iopub.status.busy": "2025-08-02T11:21:19.471413Z",
     "iopub.status.idle": "2025-08-02T11:29:50.872960Z",
     "shell.execute_reply": "2025-08-02T11:29:50.872244Z",
     "shell.execute_reply.started": "2025-08-02T11:21:19.471669Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history= model.fit(merged_ds,epochs=10,validation_data=validation_new_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691fe739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:30:57.770854Z",
     "iopub.status.busy": "2025-08-02T11:30:57.770109Z",
     "iopub.status.idle": "2025-08-02T11:30:57.960420Z",
     "shell.execute_reply": "2025-08-02T11:30:57.959709Z",
     "shell.execute_reply.started": "2025-08-02T11:30:57.770830Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'],color='red',label='train')\n",
    "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87134f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:31:01.800693Z",
     "iopub.status.busy": "2025-08-02T11:31:01.800102Z",
     "iopub.status.idle": "2025-08-02T11:31:01.828654Z",
     "shell.execute_reply": "2025-08-02T11:31:01.827932Z",
     "shell.execute_reply.started": "2025-08-02T11:31:01.800670Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_ds = validation_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c64dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:31:08.941406Z",
     "iopub.status.busy": "2025-08-02T11:31:08.940897Z",
     "iopub.status.idle": "2025-08-02T11:31:10.258558Z",
     "shell.execute_reply": "2025-08-02T11:31:10.257924Z",
     "shell.execute_reply.started": "2025-08-02T11:31:08.941384Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get one batch of validation images\n",
    "for images, labels in validation_ds.take(1):\n",
    "    preds = model.predict(images)\n",
    "    preds = tf.where(preds > 0.5, 1, 0)  # threshold for binary classification\n",
    "    break\n",
    "\n",
    "# Show predictions vs actual labels\n",
    "for i in range(10):\n",
    "    print(f\"Predicted: {preds[i].numpy()[0]}, Actual: {labels[i].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc263882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:31:30.930215Z",
     "iopub.status.busy": "2025-08-02T11:31:30.929728Z",
     "iopub.status.idle": "2025-08-02T11:31:31.855912Z",
     "shell.execute_reply": "2025-08-02T11:31:31.855357Z",
     "shell.execute_reply.started": "2025-08-02T11:31:30.930172Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess image\n",
    "img_path = '/kaggle/input/dog-vs-cat-classification/test/test/000000.jpg'  # example path\n",
    "img = image.load_img(img_path, target_size=(256, 256))\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# Normalize (important!)\n",
    "img_array = img_array / 255.0  \n",
    "\n",
    "# Add batch dimension\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(img_array)\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c35e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:31:38.951678Z",
     "iopub.status.busy": "2025-08-02T11:31:38.951429Z",
     "iopub.status.idle": "2025-08-02T11:31:39.179317Z",
     "shell.execute_reply": "2025-08-02T11:31:39.178599Z",
     "shell.execute_reply.started": "2025-08-02T11:31:38.951660Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51c21a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# MobileNetV3 Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec438a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:35:12.170853Z",
     "iopub.status.busy": "2025-08-02T11:35:12.170371Z",
     "iopub.status.idle": "2025-08-02T11:46:27.791043Z",
     "shell.execute_reply": "2025-08-02T11:46:27.790277Z",
     "shell.execute_reply.started": "2025-08-02T11:35:12.170830Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. Settings ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "num_classes = 2\n",
    "image_size = 224\n",
    "\n",
    "# --- 2. Data transforms ---\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- 3. Load datasets ---\n",
    "train_dir = '/kaggle/input/dog-vs-cat-classification/train/train'  # Adjust paths accordingly\n",
    "val_dir = '/kaggle/input/cats-and-dogs/val'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                        num_workers=2, pin_memory=True)\n",
    "\n",
    "# --- 4. Load MobileNetV3 Small pretrained ---\n",
    "model = models.mobilenet_v3_small(pretrained=True)\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# --- 5. Loss and optimizer ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# --- 6. Training loop ---\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, running_corrects = 0.0, 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(loader.dataset)\n",
    "    return epoch_loss, epoch_acc.item()\n",
    "\n",
    "def eval_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, running_corrects = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(loader.dataset)\n",
    "    return epoch_loss, epoch_acc.item()\n",
    "\n",
    "# --- 7. Main training ---\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = eval_epoch(model, val_loader, criterion, device)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "          f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f} - \"\n",
    "          f\"Val loss: {val_loss:.4f}, Val acc: {val_acc:.4f} - \"\n",
    "          f\"Time: {(end - start):.1f}s\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_mobilenetv3_small.pth')\n",
    "\n",
    "print(f\"Training complete. Best validation accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e58d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:47:31.790923Z",
     "iopub.status.busy": "2025-08-02T11:47:31.790230Z",
     "iopub.status.idle": "2025-08-02T11:47:56.460112Z",
     "shell.execute_reply": "2025-08-02T11:47:56.459266Z",
     "shell.execute_reply.started": "2025-08-02T11:47:31.790895Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe0a4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T16:53:33.049484Z",
     "iopub.status.busy": "2025-08-01T16:53:33.048785Z",
     "iopub.status.idle": "2025-08-01T16:53:33.059544Z",
     "shell.execute_reply": "2025-08-01T16:53:33.058825Z",
     "shell.execute_reply.started": "2025-08-01T16:53:33.049455Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a977f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T16:53:34.350105Z",
     "iopub.status.busy": "2025-08-01T16:53:34.349419Z",
     "iopub.status.idle": "2025-08-01T16:53:34.358372Z",
     "shell.execute_reply": "2025-08-01T16:53:34.357711Z",
     "shell.execute_reply.started": "2025-08-01T16:53:34.350080Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db253e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T16:38:07.344892Z",
     "iopub.status.busy": "2025-08-01T16:38:07.344602Z",
     "iopub.status.idle": "2025-08-01T16:38:07.428790Z",
     "shell.execute_reply": "2025-08-01T16:38:07.427969Z",
     "shell.execute_reply.started": "2025-08-01T16:38:07.344870Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# 1. Load and preprocess image\n",
    "\n",
    "img_path = '/kaggle/input/dog-vs-cat-classification/test/test/000003.jpg'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "input_tensor = transform(img)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# 2. Move to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_batch = input_batch.to(device)\n",
    "model = model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# 3. Predict\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "    # For classification, apply softmax or just take argmax of logits\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "print(f'Predicted class index: {predicted_class}')\n",
    "print(f'Class probabilities: {probabilities.cpu().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40268212",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Inception-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90d8ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Concatenate, Input, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization,Reshape,multiply\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def se_block(input_tensor, ratio=16):\n",
    "    channel_axis = -1  # for 'channels_last'\n",
    "    filters = input_tensor.shape[channel_axis]\n",
    "    \n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Reshape((1, 1, filters))(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    x = multiply([input_tensor, se])\n",
    "    return x\n",
    "# Define a simplified Inception module\n",
    "def inception_module(x, filters):\n",
    "    f1, f3_r, f3, f5_r, f5, f_pool = filters\n",
    "    \n",
    "    # Branch 1: 1x1 conv\n",
    "    branch1 = Conv2D(f1, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    \n",
    "    # Branch 2: 1x1 conv -> 3x3 conv\n",
    "    branch3 = Conv2D(f3_r, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch3 = BatchNormalization()(branch3)\n",
    "    branch3 = Conv2D(f3, (3, 3), padding='same', activation='relu')(branch3)\n",
    "    branch3 = BatchNormalization()(branch3)\n",
    "    \n",
    "    # Branch 3: 1x1 conv -> 5x5 conv\n",
    "    branch5 = Conv2D(f5_r, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch5 = BatchNormalization()(branch5)\n",
    "    branch5 = Conv2D(f5, (5, 5), padding='same', activation='relu')(branch5)\n",
    "    branch5 = BatchNormalization()(branch5)\n",
    "    \n",
    "    # Branch 4: MaxPooling -> 1x1 conv\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = Conv2D(f_pool, (1, 1), padding='same', activation='relu')(branch_pool)\n",
    "    branch_pool = BatchNormalization()(branch_pool)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    return Concatenate()([branch1, branch3, branch5, branch_pool])\n",
    "\n",
    "# Define simplified Inception-v3-inspired model\n",
    "def create_inception_v3_inspired(input_shape=(256, 256, 3)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Initial layers\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    # Inception blocks\n",
    "    x = inception_module(x, filters=[64, 48, 64, 48, 64, 32])\n",
    "    x = inception_module(x, filters=[128, 64, 128, 64, 128, 64])\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    x = inception_module(x, filters=[192, 96, 192, 96, 192, 96])\n",
    "    x = inception_module(x, filters=[256, 128, 256, 128, 256, 128])\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = se_block(x)\n",
    "    # Global pooling and dense layers\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)  # Binary output (cat or dog)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Create the model\n",
    "model_v3 = create_inception_v3_inspired()\n",
    "\n",
    "# Compile the model\n",
    "model_v3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model_v3.summary()\n",
    "\n",
    "\n",
    "\n",
    "# Train model\n",
    "history = model_v3.fit(\n",
    "    merged_ds,\n",
    "    epochs=15,\n",
    "    validation_data=validation_new_ds\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27567a22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Tuner Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a06fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T13:45:13.722088Z",
     "iopub.status.busy": "2025-08-01T13:45:13.721611Z",
     "iopub.status.idle": "2025-08-01T13:45:14.341599Z",
     "shell.execute_reply": "2025-08-01T13:45:14.340635Z",
     "shell.execute_reply.started": "2025-08-01T13:45:13.722061Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(hp):\n",
    "    inputs = Input(shape=(256, 256, 3))\n",
    "    \n",
    "    # Initial layers\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    # Inception blocks\n",
    "    x = inception_module(x, filters=[64, 48, 64, 48, 64, 32])\n",
    "    x = inception_module(x, filters=[128, 64, 128, 64, 128, 64])\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    x = inception_module(x, filters=[192, 96, 192, 96, 192, 96])\n",
    "    x = inception_module(x, filters=[256, 128, 256, 128, 256, 128])\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Add SE block\n",
    "    x = se_block(x, ratio=hp.Choice(\"se_ratio\", [8, 16, 32]))\n",
    "\n",
    "    # Global Average Pooling\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Dense layers\n",
    "    x = Dense(hp.Int(\"dense_1\", min_value=128, max_value=512, step=64), activation='relu')(x)\n",
    "    x = Dropout(hp.Float(\"dropout_rate\", 0.2, 0.5, step=0.1))(x)\n",
    "    x = Dense(hp.Int(\"dense_2\", min_value=64, max_value=256, step=64), activation='relu')(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice(\"lr\", [1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f0f05",
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-01T16:13:29.605Z",
     "iopub.execute_input": "2025-08-01T13:45:21.497021Z",
     "iopub.status.busy": "2025-08-01T13:45:21.496328Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory=\"inception_tuning\",\n",
    "    project_name=\"tune_with_se\"\n",
    ")\n",
    "\n",
    "tuner.search(merged_ds, validation_data=validation_new_ds, epochs=5)\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "\n",
    "# Optional: retrain best model longer\n",
    "best_model.fit(merged_ds, validation_data=validation_new_ds, epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2c610",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# 1. Load and preprocess image\n",
    "\n",
    "img_path = '/kaggle/input/dog-vs-cat-classification/test/test/000003.jpg'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "input_tensor = transform(img)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# 2. Move to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_batch = input_batch.to(device)\n",
    "model = model_v3.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# 3. Predict\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "    # For classification, apply softmax or just take argmax of logits\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "print(f'Predicted class index: {predicted_class}')\n",
    "print(f'Class probabilities: {probabilities.cpu().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ea812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T13:12:33.055463Z",
     "iopub.status.busy": "2025-08-01T13:12:33.054805Z",
     "iopub.status.idle": "2025-08-01T13:12:33.059629Z",
     "shell.execute_reply": "2025-08-01T13:12:33.059058Z",
     "shell.execute_reply.started": "2025-08-01T13:12:33.055439Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "def preprocess_image(img_path, target_size=(256, 256)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = img_array / 255.0  # Normalize\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4c2fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T13:43:44.071839Z",
     "iopub.status.busy": "2025-08-01T13:43:44.070936Z",
     "iopub.status.idle": "2025-08-01T13:43:45.756053Z",
     "shell.execute_reply": "2025-08-01T13:43:45.755182Z",
     "shell.execute_reply.started": "2025-08-01T13:43:44.071811Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path=\"/kaggle/input/cat-dogs/20200318_184923.jpg\"\n",
    "\n",
    "img = preprocess_image(image_path)  # replace with your file path\n",
    "animal_image= mpimg.imread(image_path)\n",
    "# Predict\n",
    "prediction = model_v3.predict(img)\n",
    "\n",
    "# Interpret prediction\n",
    "if prediction[0][0] > 0.5:\n",
    "    print(\"Predicted: Dog\")\n",
    "    \n",
    "else:\n",
    "    print(\"Predicted: Cat\")\n",
    "   \n",
    "    \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e13a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T12:32:48.222118Z",
     "iopub.status.busy": "2025-08-02T12:32:48.221248Z",
     "iopub.status.idle": "2025-08-02T12:33:03.540633Z",
     "shell.execute_reply": "2025-08-02T12:33:03.539741Z",
     "shell.execute_reply.started": "2025-08-02T12:32:48.222087Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# --- 1. Settings ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 32  # Adjust if memory issues (e.g., 16 for low-memory GPU)\n",
    "image_size = 224\n",
    "num_classes = 2\n",
    "\n",
    "# --- 2. Test transform (same as validation) ---\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- 3. Custom Test Dataset ---\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        self.images.sort()  # Sort for consistent ordering\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.test_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_name\n",
    "\n",
    "# --- 4. Load test dataset ---\n",
    "test_dir = '/kaggle/input/dog-vs-cat-classification/test/test'  # Adjust path as needed\n",
    "test_dataset = TestDataset(test_dir, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=4, pin_memory=True)\n",
    "\n",
    "# --- 5. Load trained model ---\n",
    "model = models.mobilenet_v3_small(pretrained=False)\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "model.load_state_dict(torch.load('best_mobilenetv3_small.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# --- 6. Generate predictions ---\n",
    "start_time = time.time()\n",
    "predictions = []\n",
    "image_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, img_names in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)  # Get class indices (0=cat, 1=dog)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        image_ids.extend(img_names)\n",
    "\n",
    "# --- 7. Create submission file ---\n",
    "submission = pd.DataFrame({\n",
    "    'id': image_ids,  # Use full image name as id\n",
    "    'labels': predictions  # 0=cat, 1=dog\n",
    "})\n",
    "submission = submission.sort_values(by='id')  # Sort by image name\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# --- 8. Report time and preview ---\n",
    "end_time = time.time()\n",
    "print(f\"Prediction completed in {(end_time - start_time):.1f} seconds\")\n",
    "print(\"Submission file 'submission.csv' created successfully!\")\n",
    "print(submission.head())\n",
    "\n",
    "# --- 9. Optional: Validate on a few test images ---\n",
    "for img_name, pred in zip(image_ids[:5], predictions[:5]):\n",
    "    label = 'dog' if pred == 1 else 'cat'\n",
    "    print(f\"Image: {img_name}, Predicted: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3980deb0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 3218632,
     "sourceId": 34426,
     "sourceType": "competition"
    },
    {
     "datasetId": 3917177,
     "sourceId": 6809272,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7988349,
     "sourceId": 12641389,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7988386,
     "sourceId": 12641454,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67.248813,
   "end_time": "2025-08-02T12:44:43.080059",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-02T12:43:35.831246",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
